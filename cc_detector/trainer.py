import pandas as pd
import numpy as np
from pandas.core.frame import DataFrame

from cc_detector.data import ChessData

from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import RMSprop


class Trainer():
    def __init__(self) -> None:
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None

        self.model = None

    def get_data(self,
                 data_path="/Users/manuel/code/VPeron/cc_detector/raw_data/Fics_data_pc_data.pgn",
                 import_lim=1000) -> DataFrame:
        '''
        Takes a path to a pgn file (data_path) and a max. number of games read (default: import_lim=1000),
        returns three dataframes (player_df, game_df, move_df).
        '''
        player_df, game_df, move_df = ChessData().import_data(data_path=data_path,
                                                              import_lim=import_lim)

        return player_df, game_df, move_df

    def transform_data(self, move_df):
        """
        Takes the move dataframe (move_df) and transforms the data into numpy arrays
        ready to be passed to an DL model (data is already padded with value -999)
        """
        X, y = ChessData().feature_df_maker(move_df=move_df)

        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2)

        print("Data has been transformed into the correct format.")

    def train_model(self, verbose=0):
        """
        Builds an LSTM model, compiles it, and then fits it to the data transformed
        with the transform_data() function. Returns the trained model
        """
        model = Sequential()

        model.add(
            layers.Masking(mask_value=-999,
                           input_shape=(self.X_train.shape[1],
                                                self.X_train.shape[2])))
        model.add(layers.LSTM(units=128, activation='tanh', return_sequences=True))
        model.add(layers.Dropout(0.2))
        model.add(layers.LSTM(units=64, activation='tanh', return_sequences=False))
        model.add(layers.Dropout(0.2))
        model.add(layers.Dense(32, activation='relu'))
        model.add(layers.Dense(16, activation='relu'))
        model.add(layers.Dense(units=1, activation="sigmoid"))

        # The compilation
        rmsprop_opt = RMSprop(learning_rate=0.001)

        model.compile(loss='binary_crossentropy',
                      optimizer=rmsprop_opt,
                      metrics=["accuracy"])


        # The fit
        es = EarlyStopping(restore_best_weights=True, patience=5)

        model.fit(self.X_train, self.y_train,
                  batch_size=32,
                  epochs=50,
                  callbacks=[es],
                  validation_split=0.2,
                  verbose=verbose)

        self.model = model

        print("Model has been trained ðŸ’ª")

        return self.model

    def evaluate_model(self):
        """
        Evaluates the model based on the test data that was generated by the
        transform_data() function.
        """
        result = self.model.evaluate(x=self.X_test, y=self.y_test)

        return result
